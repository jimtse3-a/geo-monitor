name: Daily Hotwords Collection V2.0

on:
  schedule:
    # 每天早8点和晚8点各执行一次（北京时间）
    - cron: '0 0 * * *'  # UTC 00:00 = 北京 08:00
    - cron: '0 12 * * *' # UTC 12:00 = 北京 20:00
  
  # 支持手动触发
  workflow_dispatch:
    inputs:
      platform:
        description: '指定AI平台 (all/kimi/deepseek/yuanbao/qianwen/wenxin/doubao)'
        required: false
        default: 'all'

env:
  # 飞书配置
  FEISHU_APP_ID: ${{ secrets.FEISHU_APP_ID }}
  FEISHU_SECRET: ${{ secrets.FEISHU_SECRET }}
  FEISHU_BASEID: ${{ secrets.FEISHU_BASEID }}
  TABLE_TRENDS: ${{ secrets.TABLE_TRENDS }}
  TABLE_SKU: ${{ secrets.TABLE_SKU }}
  
  # AI平台API密钥
  KIMI_API_KEY: ${{ secrets.KIMI_API_KEY }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
  YUANBAO_API_KEY: ${{ secrets.YUANBAO_API_KEY }}
  QIANWEN_API_KEY: ${{ secrets.QIANWEN_API_KEY }}
  WENXIN_API_KEY: ${{ secrets.WENXIN_API_KEY }}
  DOUBAO_API_KEY: ${{ secrets.DOUBAO_API_KEY }}

jobs:
  collect:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests
    
    - name: Run hotwords crawler V2.0
      run: |
        echo "开始热词抓取任务 - $(date '+%Y-%m-%d %H:%M:%S')"
        python crawlers/hotwords_crawler.py
        echo "任务完成 - $(date '+%Y-%m-%d %H:%M:%S')"
    
    - name: Upload logs on failure
      if: failure()
      run: |
        echo "任务执行失败，请检查日志"
